{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa2186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.1951 - accuracy: 0.9426 - val_loss: 0.0761 - val_accuracy: 0.9755\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0599 - accuracy: 0.9819 - val_loss: 0.0604 - val_accuracy: 0.9801\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 0.0358 - accuracy: 0.9894 - val_loss: 0.0531 - val_accuracy: 0.9824\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 28s 59ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 0.0552 - val_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 32s 68ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.0591 - val_accuracy: 0.9805\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.0629 - val_accuracy: 0.9822\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 27s 58ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0606 - val_accuracy: 0.9831\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0623 - val_accuracy: 0.9839\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0592 - val_accuracy: 0.9842\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0647 - val_accuracy: 0.9827\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=\"created by layer 'conv2d_input'\"), but it was called on an input with incompatible shape (None, 28, 28, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 28, 28, 3)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 28, 28, 3), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mC:\\USJR Projects\\CS ELEC 1\\convolutional-neural-network\\cnn.py:53\u001b[0m\n\u001b[0;32m     51\u001b[0m test_image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(test_image)\n\u001b[0;32m     52\u001b[0m test_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(test_image, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m training_set\u001b[38;5;241m.\u001b[39mclass_indices\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\GWENAL~1\\AppData\\Local\\Temp\\__autograph_generated_fileuvwaswwo.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 28, 28, 3)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 28, 28, 3), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "%run cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32ab6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.1954 - accuracy: 0.9434 - val_loss: 0.0768 - val_accuracy: 0.9760\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 0.0573 - accuracy: 0.9827 - val_loss: 0.0553 - val_accuracy: 0.9813\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 35s 75ms/step - loss: 0.0340 - accuracy: 0.9896 - val_loss: 0.0519 - val_accuracy: 0.9819\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 29s 61ms/step - loss: 0.0211 - accuracy: 0.9937 - val_loss: 0.0506 - val_accuracy: 0.9838\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 28s 60ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0500 - val_accuracy: 0.9836\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.0540 - val_accuracy: 0.9837\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0496 - val_accuracy: 0.9853\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0691 - val_accuracy: 0.9814\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.0647 - val_accuracy: 0.9830\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 29s 62ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0615 - val_accuracy: 0.9839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x222c41d2a70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras imports for the dataset and building our neural network\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "# to calculate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.utils as image\n",
    "import numpy as np\n",
    "\n",
    "# loading the dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# building the input vector from the 28x28 pixels\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)\n",
    "\n",
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "# convolutional layer\n",
    "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "# hidden layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47f4bc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='conv2d_1_input'), name='conv2d_1_input', description=\"created by layer 'conv2d_1_input'\"), but it was called on an input with incompatible shape (None, 28, 28, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_1' (type Sequential).\n    \n    Input 0 of layer \"conv2d_1\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 28, 28, 3)\n    \n    Call arguments received by layer 'sequential_1' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 28, 28, 3), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m test_image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(test_image)\n\u001b[0;32m      3\u001b[0m test_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(test_image, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m training_set\u001b[38;5;241m.\u001b[39mclass_indices\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Users\\GWENAL~1\\AppData\\Local\\Temp\\__autograph_generated_fileuvwaswwo.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Gwen Alunan\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_1' (type Sequential).\n    \n    Input 0 of layer \"conv2d_1\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 28, 28, 3)\n    \n    Call arguments received by layer 'sequential_1' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 28, 28, 3), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/six.png', target_size = (28, 28, 1))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc755858",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/single_prediction/six.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m img_reverted\u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mbitwise_not(img)\n\u001b[0;32m      3\u001b[0m test_image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mload_img(img_reverted, target_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('dataset/single_prediction/six.png', 0)\n",
    "img_reverted= cv2.bitwise_not(img)\n",
    "test_image = image.load_img(img_reverted, target_size = (28, 28, 1))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a6c05bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1865d94",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "path should be path-like or io.BytesIO, not <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/single_prediction/six.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m img_reverted\u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mbitwise_not(img)\n\u001b[1;32m----> 3\u001b[0m test_image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_reverted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m test_image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(test_image)\n\u001b[0;32m      5\u001b[0m test_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(test_image, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\image_utils.py:425\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    423\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    426\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath should be path-like or io.BytesIO, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    427\u001b[0m     )\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m color_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;66;03m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001b[39;00m\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;66;03m# convert it to an 8-bit grayscale image.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mTypeError\u001b[0m: path should be path-like or io.BytesIO, not <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('dataset/single_prediction/six.png', 0)\n",
    "img_reverted= cv2.bitwise_not(img)\n",
    "test_image = image.load_img(img_reverted, target_size = (28, 28, 1))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8155ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'training_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m test_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(test_image, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_image)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtraining_set\u001b[49m\u001b[38;5;241m.\u001b[39mclass_indices\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_set' is not defined"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/six.png', target_size = (28, 28), color_mode = \"grayscale\")\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "749ac626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/six.png', target_size = (28, 28), color_mode = \"grayscale\")\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "# training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c2202b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85001b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/six.png', target_size = (28, 28), color_mode = \"grayscale\")\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "# training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "512afa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/seven.png', target_size = (28, 28), color_mode = \"grayscale\")\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "# training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4319e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/six.png', target_size = (28, 28), color_mode = \"grayscale\", keep_aspect_ratio = True)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "# training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92490564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/seven.png', target_size = (28, 28), color_mode = \"grayscale\", keep_aspect_ratio = True)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "# training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6eeec50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/eight.png', target_size = (28, 28), color_mode = \"grayscale\", keep_aspect_ratio = True)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "# training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55f85866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_image)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# training_set.class_indices\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m(\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/seven.png', target_size = (28, 28), color_mode = \"grayscale\", keep_aspect_ratio = True)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "# training_set.class_indices\n",
    "print(result.index(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8712a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "[[0.09596168 0.1371111  0.10396745 0.08915977 0.101616   0.1067867\n",
      "  0.091468   0.11336916 0.07407952 0.08648067]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/two.png', target_size = (28, 28), color_mode = \"grayscale\", keep_aspect_ratio = True)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "# training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00d1582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/four.png', target_size = (28, 28), color_mode = \"grayscale\", keep_aspect_ratio = True)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "# training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6acad7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/seven.png', target_size = (28, 28), color_mode = \"grayscale\", keep_aspect_ratio = True)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "# training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ee3f455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/seven.png', target_size = (28, 28), color_mode = \"grayscale\", keep_aspect_ratio = True)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "# training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2893daf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/four.png', target_size = (28, 28), color_mode = \"grayscale\", keep_aspect_ratio = True)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "# training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91aa3cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/four.png', target_size = (28, 28), color_mode = \"grayscale\", keep_aspect_ratio = True)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "# training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80abb740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_image)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# training_set.class_indices\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnumpy\u001b[49m\u001b[38;5;241m.\u001b[39mwhere(result \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('dataset/single_prediction/seven.png', target_size = (28, 28), color_mode = \"grayscale\", keep_aspect_ratio = True)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "# training_set.class_indices\n",
    "print(numpy.where(result == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfaf1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
